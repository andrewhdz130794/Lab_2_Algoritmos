# -*- coding: utf-8 -*-
"""gradiante.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_RAt5rgrfiVMHWptY9T8NuEj_q_sZwbU

# Problema #1
"""

import numpy as np
import pandas


def gradient_descent(Q, c, x0, epsilon, N, alpha_strategy, alpha):
    """
    Implementación del algoritmo Gradient Descent para una función cuadrática.

    Parametrors:
    - Q: Matriz simétrica y definida positiva.
    - c: Vector de coeficientes.
    - x0: Punto inicial.
    - epsilon: Tolerancia para la norma del gradiente.
    - N: Número máximo de iteraciones.
    - alpha_strategy: Estrategia para el step size (exacto, constante, variable).

    Returns:
    - history: Lista con las iteraciones (k, x_k, p_k, ||∇f(x_k)||).
    """

    arrayk = []
    arrayx = []
    arrayp_k = []
    arraygrad_norm = []



    def gradient(x):
        return np.dot(Q, x) + c

    def exact_step_size(x, grad):
        return np.dot(grad, grad) / np.dot(np.dot(grad, Q), grad)

    x = x0
    # history = []

    for k in range(N):
        grad = gradient(x)
        grad_norm = np.linalg.norm(grad)

        if grad_norm < epsilon:
            break

        if alpha_strategy == 'exacto':
            alpha_k = exact_step_size(x, grad)
        elif alpha_strategy == 'constante':
            alpha_k = alpha
        elif alpha_strategy == 'variable':
            alpha_k = 1 / (k + 1)

        p_k = -grad
        x = x + alpha_k * p_k

        print("k",k)
        arrayk.append(k + 1)

        string_x = ' '.join(f'{num:.2f}' for num in x)
        arrayx.append(string_x) 

        string_p_k = ' '.join(f'{num:.2f}' for num in p_k)
        arrayp_k.append(string_p_k) 

        print("grad_norm",grad_norm)
        arraygrad_norm.append(grad_norm)
        # history.append((k, x, p_k, grad_norm))

    TableOut = pandas.DataFrame({'Iter':arrayk, 'Xn':arrayx, 'P_k': arrayp_k, 'P_grad': arraygrad_norm})
    return TableOut
# # Aqui se ingresan los valores del parametro (como aparecen en el ejercicio)
# Q = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])
# c = np.array([1, 0, 1])
# x0 = np.array([3, 5, 7])
# epsilon = 1e-6
# N = 30
# for alpha_strategy in ['exact', 'constant', 'variable']:
#     result = gradient_descent(Q, c, x0, epsilon, N, alpha_strategy)

#     print(f"Resultados para alpha_strategy = {alpha_strategy}")
#     print("k\t x_k\t\t p_k\t\t ||∇f(x_k)||")
#     for k, x_k, p_k, grad_norm in result:
#         print(f"{k}\t {x_k}\t {p_k}\t {grad_norm}")
#     print("\n")

"""# Problema #2"""

import numpy as np

def rosenbrock_function(x):
    """Calcula el valor de la función de Rosenbrock."""
    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2

def rosenbrock_gradient(x):
    """Calcula el gradiente de la función de Rosenbrock."""
    dfdx1 = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])
    dfdx2 = 200 * (x[1] - x[0]**2)
    return np.array([dfdx1, dfdx2])

def gradient_descent_rosenbrock(x0, alpha, epsilon, N):
    """
    Implementación del algoritmo Gradient Descent para la función de Rosenbrock.

    Parametros:
    - x0: Punto inicial.
    - alpha: Step size constante.
    - epsilon: Tolerancia para la norma del gradiente.
    - N: Número máximo de iteraciones.

    Returns:
    - history: Lista con las iteraciones (k, x_k, p_k, ||∇f(x_k)||).
    """
    x = x0
    history = []
    arrayk = []
    arrayx = []
    arrayp_k = []
    arraygrad_norm = []

    for k in range(N):
        grad = rosenbrock_gradient(x)
        grad_norm = np.linalg.norm(grad)

        if grad_norm < epsilon:
            break

        p_k = -grad
        x = x + alpha * p_k

        print("k",k)
        arrayk.append(k + 1)

        string_x = ' '.join(f'{num:.2f}' for num in x)
        arrayx.append(string_x) 

        string_p_k = ' '.join(f'{num:.2f}' for num in p_k)
        arrayp_k.append(string_p_k) 

        print("grad_norm",grad_norm)
        arraygrad_norm.append(grad_norm)
        history.append((k, x.copy(), p_k.copy(), grad_norm))

    TableOut = pandas.DataFrame({'Iter':arrayk, 'Xn':arrayx, 'P_k': arrayp_k, 'P_grad': arraygrad_norm})
    return TableOut

# # Aqui se colocan los paramertros que se desean evaliar del problema
# x0 = np.array([0, 0])
# alpha = 0.05
# epsilon = 1e-8
# N = 1000

# # Ejecutar el algoritmo
# result = gradient_descent_rosenbrock(x0, alpha, epsilon, N)

# # Mostrar los resultados
# print("Resultados para la función de Rosenbrock")
# print("k\t x_k\t\t\t\t p_k\t\t\t ||∇f(x_k)||")
# for k, x_k, p_k, grad_norm in result:
#     print(f"{k}\t {x_k}\t {p_k}\t {grad_norm}")